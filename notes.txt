https://spacelift.io/blog/terraform-apply

terraform resource block(s)

aws help
aws iam help
aws ec2 help
aws iam create-user help 

gitops for terraform with atlantis
==================
https://ruan.dev/blog/2024/08/04/step-by-step-guide-to-setting-up-atlantis-with-gitlab
https://www.youtube.com/watch?v=ICYhgIK_c8o


/root/.aws/config
 /root/.aws/credential

aws --endpoint http://aws:4566 iam list-users

workspaces in terraform
===================
think relation between terraform modules and workspaces 
think??for prod env ,can you use modueles from NP env??

tree folder-name 
terrafom workspace new project-name 
terrafom workspace select workspac-name 
terraform workspace list 
terraform.workspace>to get current workspace value 

lookup(var.ami,terrafom.workspace)
ami=lookup(var.ami,terrafom.workspace)

terraform>>immutable >>recreates resources after changing values

we can also create different workspaces for differtn enviromenmts 

configuration files,configuration directory(tf files)

terraform arguments>>resource params or attributes

terraform state >>json file structure
commands
=========
terraform show
What is the id of the file resource we just created?

Run terraform show or terraform state show local_file.file to find out.
.terraform/providers >>plugins/providers installed

terraform apply -var "filename =/root/pet.txt" -var "length =2"
export TF_VAR_file ='/root/pets.txt'
terraform apply
terraform apply -auto-approve

Use the terraform show command to inspect the terraform.tfstate file.

terraform apply -var-file variables.tfvars
 terraform output #print all out variables values
 terraform output pet-name 

 terraform plan --refresh =false

terraform validate 

terraform fmt 

terrafom console

terraform show>>display current state of configuration/resources
terraform show -json
terraform providers 
terraform state list>>less details
terraform state list aws_s3_bucket.bucket-name
terraform show>>more details
terraform state pull >>for pulling remote state file
terraform state rm aws_s3_bucket.bucket-name

terraform taint aws_instance.web_server
terraform untaint aws_instance.web_server
terraform graph 

export TF_LOG = <log_level>
export TF_LOG = TRACE
export TF_LOG_PATH =/tmp/folder
unset TF_LOG_PATH

head -10 filename


 we can use outputs as inputs for Ansible or shell scripts etc 

When you run terraform plan, Terraform will compare the current state of the infrastructure (stored in the state file) with the desired configuration (from your .tf files) and report any differences (drift). For the example above, it would show something like this:

 The terraform plan and Refresh Process
When you run terraform plan, Terraform does the following:

Refreshes the state: It queries the cloud provider for the current properties of all resources in your configuration. For example, Terraform will call AWS APIs to get the current instance type of the EC2 instance.
Compares the desired state (your .tf files) with the actual state (from AWS, for example):
Terraform checks the configuration you've defined in the .tf files and looks at the state file to see what Terraform thinks the instance type should be.
It then fetches the actual state of the EC2 instance (by querying AWS) to see what the instance type is in reality.

The Refresh Behavior
By default, terraform plan automatically performs a refresh before comparing the desired and actual states. This ensures Terraform has the most up-to-date information about the infrastructure.
If you want to disable the refresh (e.g., for performance reasons or if you want to ignore the current state of resources temporarily), you can use the -refresh=false flag:

configuration directory>>tf files exits
Types of IAC 
=======
Ansible:configuration management
Terraform: provisioning tool
docker: server templating

terraform>>immutable 
terraform latest version>Version: 1.10.5(jan'25)

HCL:Hashicorp language>declarative language

Cloudformation>>AWS specific>not cloud agnostic

desired state(code/tf files) > current state(deployed/actual)

terraform init command does not create a state file. For a state file to be created, you must run terraform apply must be run at least once.

Resources >>Terraform objects

idempotent:only desired changes are applied,doesn't recreate Resources after re-run of the same 
script

docker-immutable-recreates containers for the changes applied


Terraform core is responsible for reading the configuration files (written in HCL) and generating the execution plan to achieve the desired state of your infrastructure.
It interacts with various plugins known as providers that are responsible for managing different types of resources.
Terraform core uses State to keep track of the current state of the infrastructure. It compares the desired state (defined in the code) with the current state and determines what needs to be created, updated, or deleted


Providers are the plugins that interact with APIs of different cloud platforms (like AWS, Azure) or services (like MySQL, Kubernetes).
For AWS, Terraform uses the AWS Provider, which contains the logic to communicate with AWS APIs and create/manage resources like EC2, S3, RDS, etc

State Management:

Terraform keeps track of the infrastructure's current state in a state file (terraform.tfstate).
This state file is crucial as Terraform uses it to detect any changes between your configuration and the actual resources.
The state can be stored locally or remotely (like in an S3 bucket) for collaboration.


API Calls:

Terraform uses the AWS SDK (software development kit) in the AWS provider to make API calls to AWS services. These API requests are what actually provision, update, or destroy infrastructure components.

Modules:

A module in Terraform is a container for multiple resources that are used together. Modules are a way to organize and reuse configuration by grouping related resources.
You can create modules to encapsulate common configurations and reuse them across different environments or projects.

Data Sources:

Data sources allow you to fetch data from external sources (like AWS services) and use it in your Terraform configurations. This data doesn't create resources but retrieves information to use in your setup.

Outputs:

Outputs define the information that should be returned after Terraform has run. This is helpful for exposing details like IP addresses or IDs of created resources.

Restoring from Backup:

If something goes wrong with your terraform.tfstate file, you can restore from the backup (terraform.tfstate.backup).
By simply renaming the backup file to terraform.tfstate (or copying its content), you can restore the state to the point where it was when the backup was taken.
mv terraform.tfstate.backup terraform.tfstate


Terraform does use a caching mechanism to avoid the reinstallation of previously used providers and plugins. This helps speed up the process of initializing and running Terraform commands, especially if the environment hasn’t changed.


Export variables using the prefix TF_VAR_ followed by the variable name and a value.

To view the attributes actually exported by the resource, run terraform apply followed by terraform show:

The terraform.tfstate file and the terraform show command are closely related because they both deal with the current state of your infrastructure as managed by Terraform.
The terraform show command provides a human-readable view of the current state of your infrastructure, which is stored in the terraform.tfstate file.

The .terraform.lock.hcl file is Terraform's dependency lock file. It plays a crucial role in ensuring that the exact versions of providers used in your Terraform configuration are consistent across all environments and executions.
To update the lock file (i.e., after a provider update), you can run terraform init -upgrade.

tf state file is generated by terraform apply command 

by default terraform destroy resource first before recreating next,but this can
be overriddern with lifecycle rules

The terraform apply failed in spite of our validation working! This is because the validate command only carries out a general verification of the configuration. It validated the resource block and the argument syntax but not the values the arguments expect for a specific resource!

the terraform validate command only checks if the Terraform configuration files are syntactically correct and if the general structure of the resources is valid, but it does not verify if the provided values for specific resources are valid according to the provider's expectations.

terraform validate: Checks if the Terraform code is syntactically correct and if the resource configuration is logically sound according to Terraform’s structure but does not validate the correctness of the values for a specific provider.
terraform apply: Actually interacts with the cloud provider and verifies if the values (like the AMI) are valid for that provider, so errors related to invalid values can only occur at this stage.

Where did the file go?!!?

If you observe the output of the previous apply (scroll up!), you will see that the lifecycle rule we applied caused the local file to the created first and the same file to be destroyed during the recreate operation.


This goes to show that it is not always advisable to use this rule!

In this example, the filename argument for the local_file resource has to be unique which means that we cannot have two instances of the same file created at the same time!
The random_string resource on the other hand is a logical resource that is only recorded in the state and does not have such a restriction.

If you run terraform apply again, the file resource will be created as it does not exist currently.

meta arguments
===========
depends_on ,lifecycle,count,for-each

Use Terraform remote state locking (e.g., when storing state in S3 with DynamoDB for locking) to ensure only one operation can modify the state at a time.

Use terraform state commands: Sometimes, state repair commands (like terraform state rm, terraform state pull, terraform state push) can help to clean up or update the corrupted state.
Rebuild the state: If all else fails, you may have to manually rebuild the state file using terraform import to re-associate Terraform resources with the existing infrastructur

terraform force-unlock LOCK_ID

terraform state rm: Remove a resource from the Terraform state
Use Case: This command is used when you need to remove a resource from the state file without affecting the actual infrastructure. It is useful when:

A resource was manually deleted outside of Terraform (e.g., directly in the cloud provider's console).
You want to stop managing a resource via Terraform but do not want to destroy it immediately.
You want to re-import or rebuild a resource after fixing issues or corruption.
Example:

bash
Copy
Edit
terraform state rm aws_instance.my_instance

terraform state pull: Retrieve and display the current state
Use Case: This command pulls the current state file and displays it in JSON format. It is useful for:

Inspecting the current state file.
Backing up the state manually.
Debugging issues in the state file (e.g., identifying corruption or mismatches between the state and actual infrastructure).
Working offline with the state (for example, to edit the state file locally before pushing changes).
Example:

bash
Copy
Edit
terraform state pull > backup.tfstate

terraform state push: Update the remote state file with local changes
Use Case: This command is used to push a local state file to the remote backend (e.g., S3, Terraform Cloud, etc.) after making manual changes or recovering from corruption. It is useful when:

You have manually fixed the state file (e.g., removed problematic entries) and need to push the corrected state to the remote backend.
You need to recover from a corrupted or inconsistent state by restoring a backup or manually modified state file.
You're transitioning the state from local to remote or moving between backends.
Example:

bash
Copy
Edit
terraform state push backup.tfstate
Scenario 4: Correcting state after a failed apply
A Terraform apply was interrupted, leaving the state in an inconsistent state (e.g., some resources were created, others were not).
Inspect the state using terraform state pull to see what resources were applied successfully.
Optionally use terraform state rm to remove problematic or incomplete resources from the state.
Re-run terraform apply to bring the infrastructure back into the desired state.

Minio provides an S3-compatible API and allows us to configure the s3 backend in the same way as the actual S3 service in AWS Cloud.

important>>terraform  plan or terraform plan -generate-config-out=ourfilename.tf 
use this generated file as blueprint to recrate or reuse >>to import terraform resources
after run terraform  plan or terraform plan -generate-config-out=ourfilename.tf 
use this generated file as blueprint to recrate or reuse 
alternative option is put dummy resouce block (to imported)-after run terraform import>>resource
will be imported into terra statefile and then put this values in dummy resource block
created with the attributes imported 

terraform get >>to download module from registry 

The .terraform.tfstate.lock.info file is a lock file created by Terraform to prevent concurrent operations that could corrupt the Terraform state file (terraform.tfstate). Here’s what it indicates and how it behaves:

Run terraform show to see details of all the resources. To see just the list of resources from the state run terraform state list.

aws ec2 create-key-pair --endpoint http://aws:4566 --key-name jade --query 'KeyMaterial' --output text > /root/terraform-projects/project-jade/jade.pem.

aws ec2 describe-instances --endpoint http://aws:4566  --filters "Name=image-id,Values=ami-082b3eca746b12a89" | jq -r '.Reservations[].Instances[].InstanceId'

i-77cdfd6a0d3a45cd9



% terraform import aws_instance.jade i-ad62b33071bfd4bf3

important
========
terraform import aws_instance.jade i-ad62b33071bfd4bf3>>this will import values in statefile
but out plan config import >>will not update or refresh statfile 

packer can be used to build custom ami(instead of installing after resouce creation)

important
=======
In this case, an instance will be modified, but nginx will not be installed. It is due to the fact that User data scripts only run at first boot whereas the instance modification causes a reboot.
terraform apply -auto-approve

important
==========
let's say you give a bucketname which not following bucketname rules,
in terrform plan ,you do not get any erros,but in apply you will get erros

terraform plan: This step does a dry run to calculate what resources need to be created or changed, but it doesn't interact with the actual AWS API for creating resources. Terraform can check if your configuration is syntactically correct, but it does not verify resource names or attempt to provision them during this phase.

terraform apply: This step actually communicates with AWS to create or modify resources. During this interaction, the bucket name you specified (dc_is_better_than_marvel) is sent to AWS, and AWS validates whether it's a valid S3 bucket name.

As explained in the Lab Demonstration video, we are making use of localstack as the mocking framework to work with AWS.